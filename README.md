# üìä MACHINE LEARNING: EVALUACI√ìN DE MODELOS

[![Python](https://img.shields.io/badge/Python-3670A0?style=flat&logo=python&logoColor=ffdd54)](https://www.python.org/)¬†¬†
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)¬†¬†
[![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)](https://pandas.pydata.org/)

Este proyecto es esencial en el flujo de trabajo de Machine Learning, centr√°ndose en la **Evaluaci√≥n de Modelos** para asegurar su fiabilidad y capacidad de generalizaci√≥n. Se explora c√≥mo la **aleatoriedad inicial** afecta el rendimiento del modelo y se introducen t√©cnicas avanzadas como la **Validaci√≥n Cruzada (K-Fold)** y el uso de **Pipelines** para lograr una evaluaci√≥n robusta y objetiva.

---

## üß† Contenido del Proyecto

### 1Ô∏è‚É£ La Influencia de la Aleatoriedad
- **Problema:** La divisi√≥n inicial de los datos en conjuntos de entrenamiento y prueba es un proceso aleatorio, lo que significa que el **Accuracy** (o m√©trica de rendimiento) del modelo puede variar significativamente cada vez que se ejecuta el proceso.
- **Soluci√≥n:** Se demuestra que fijar el par√°metro `random_state` es crucial para garantizar la **reproducibilidad** de los resultados.

### 2Ô∏è‚É£ Evaluaci√≥n Robusta: Validaci√≥n Cruzada (Cross-Validation)
Para obtener una m√©trica de rendimiento m√°s estable y objetiva, se utiliza la t√©cnica de Validaci√≥n Cruzada:

- **K-Fold Cross-Validation:** El dataset se divide en *K* subconjuntos (o *folds*). El modelo se entrena *K* veces, utilizando *K-1* *folds* para entrenamiento y el *fold* restante para prueba. La m√©trica final es el promedio de los *K* resultados.
- **Group K-Fold:** Se utiliza una versi√≥n avanzada (`GroupKFold`) que es vital cuando hay **datos con correlaci√≥n interna** (ej. varios registros de un mismo cliente o, en el ejemplo, diferentes "modelos de carro"). Esta t√©cnica asegura que las muestras de un mismo grupo **nunca** est√©n en los conjuntos de entrenamiento y prueba simult√°neamente, evitando as√≠ la fuga de informaci√≥n.

### 3Ô∏è‚É£ Estandarizaci√≥n del Flujo de Trabajo (Pipelines)
- **Necesidad:** En modelos complejos (como la Regresi√≥n Lineal), a menudo se requieren pasos previos al entrenamiento (ej. transformaciones, escalado de variables).
- **Pipeline de Scikit-learn:** Se introduce el uso de `Pipeline` como una soluci√≥n elegante para encadenar estos pasos de preprocesamiento con el modelo final. Esto garantiza que la validaci√≥n cruzada aplique correctamente las transformaciones en **cada uno de los *folds***, manteniendo la integridad del proceso de evaluaci√≥n.

---

## üõ†Ô∏è Librer√≠as Utilizadas

| Librer√≠a | Uso principal |
|:---:|:---:|
| **Scikit-learn** | Implementaci√≥n de la Validaci√≥n Cruzada (`KFold`, `GroupKFold`) y la construcci√≥n de `Pipeline`|
| **Pandas** | Carga y manipulaci√≥n del dataset de veh√≠culos|

---

## üéØ Objetivo del Proyecto
Capacitar al usuario para evaluar de manera **s√≥lida, objetiva y reproducible** cualquier modelo de Machine Learning, superando las limitaciones de la simple divisi√≥n `train_test_split`. El proyecto garantiza que el usuario pueda utilizar t√©cnicas avanzadas como `GroupKFold` y `Pipeline` para manejar situaciones complejas en la evaluaci√≥n.

---

## üìà Resultados Clave
- Se demuestra c√≥mo la **Validaci√≥n Cruzada** produce una **m√©trica de rendimiento m√°s estable y representativa** que una √∫nica divisi√≥n aleatoria.
- Se utiliza `GroupKFold` para simular la **entrada de datos nuevos o no disponibles** durante el entrenamiento, obteniendo una evaluaci√≥n m√°s realista del modelo en producci√≥n.
- Se implementa el **Pipeline** para encapsular y ejecutar correctamente los pasos de preprocesamiento, asegurando un proceso de entrenamiento y validaci√≥n eficiente.

